# âœ‹ Hand Volume Controller ğŸ”Š  
### Control system volume using hand gestures â€” touchless & seamless!

![Python](https://img.shields.io/badge/python-3.8+-blue)
![License](https://img.shields.io/badge/license-MIT-green)

A smart and fun Computer Vision project that allows you to control your system's volume **without touching the keyboard or mouse**
Show your hand to the webcam and control audio with intuitive gestures.

## ğŸ–¼ï¸ Screenshots
    > ![Demo](assets/image.png)


## Features

- Real-time hand tracking (MediaPipe)
- Single-hand control: thumb + index finger distance
- Dual-hand mode: left thumb â†” right index
- Smooth interpolation-based volume control
- Live UI overlay (volume bar & fingertip connection)
- Logging for debugging and performance

## ğŸ§° Tech Stack

| Technology | Purpose |
|------------|---------|
| Python     | Core language |
| MediaPipe  | Hand landmark detection |
| OpenCV     | Camera processing & UI overlays |
| PyCaw      | Windows system volume control |
| NumPy      | Distance calculations & interpolation |

## ğŸ“‚ Project Structure

hand-volume-controller/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ src/
â”œâ”€â”€ volume_controller.py
â”œâ”€â”€ hand_detector.py
â”œâ”€â”€ audio/
â”‚ â””â”€â”€ volume_manager.py
â”œâ”€â”€ ui/
â”‚ â””â”€â”€ overlay.py
â””â”€â”€ utils/
â””â”€â”€ logger.py
â”œâ”€â”€ assests/
â”‚ â””â”€â”€ image.png


## âš™ï¸ Installation

### 1. Clone
git clone https://github.com/YOUR_USERNAME/hand-volume-controller.git
cd hand-volume-controller

### 2. Create Environment
python -m venv venv
# Windows
venv\Scripts\activate

### 3. Install dependencies
pip install -r requirements.txt

### 4. Run application
python main.py


## âœ‹ Gesture Controls

| Gesture | Action |
|--------:|--------|
| Thumb + Index (same hand) | Smooth volume control (either hand) |
| Left Thumb + Right Index   | Dual-hand volume control |
| Fingers move apart         | Increase volume ğŸ”Š |
| Fingers move close         | Decrease volume ğŸ”‰ |
| No gesture                 | Volume remains stable |


## ğŸ” How It Works

1. MediaPipe detects hands and returns 21 landmarks per hand.  
2. We track thumb tip (#4) and index tip (#8).  
3. Compute Euclidean distance between active fingertips.  
4. Map distance to volume percentage using `np.interp`.  
5. Apply volume with PyCaw and show UI overlay in real-time.

## ğŸ‘¨â€ğŸ’» Author

**Shubham Shinde**  
AI â€¢ ML â€¢ Computer Vision Enthusiast  
shinde.ashubham@gmail.com

## â­ Show your support

If you like the project, please star the repo â€” it helps a lot!
